# Queue SpinLock

Реализуйте честный масштабируемый спинлок, в котором не будет сценариев _false sharing_ и _thundering herd_.

## Ticket Lock

Вспомним, как устроен [`TicketLock`](/tasks/mutex/try-lock):

В `TicketLock` потоки выстраиваются в очередь, получая от атомарного счетчика последовательные номерки. Очередь – "виртуальная", в спинлоке хранится "голова" очереди – `owner_ticket` – номерок текущего владельца спинлока, и "хвост" этой очереди – `next_free_ticket` – следующий свободный номерок.

## Когерентность

Виртуальная очередь в `TicketLock` неоптимальна с точки зрения протокола когерентности кэшей:

- _False sharing_: получая номерок с помощью `next_free_ticket_.fetch_add(1)`, поток инвалидирует кэш-линию с `owner_ticket_`, тем самым заставляя перечитывать ее других waiter-ов.

- _Thundering herd_: после `Unlock` каждый waiter в цикле ожидания перечитывает кэш-линию с `owner_ticket_`. 

### Идея

Заменим виртуальную очередь на явную, что позволит потокам вставать в очередь / передавать владение без избыточных инвалидаций у waiter-ов.

## Очередь

Для начала рассмотрим вспомогательную конструкцию – *multi-producer / single-consumer* очередь на атомарных операциях, без привязки к спинлокам и очередям ожидания.

Очередь представим односвязным списком, в котором указатели ориентированы от головы списка к хвосту. Элементы добавляются в хвост списка и извлекаются из головы.

Вставка двухфазная:

Поток, который хочет добавить собственный узел `new_node` в очередь,

1. Атомарно "захватывает" текущий хвост списка `tail`, подменяя его на свой узел, с помощью `prev_tail = tail.exchange(new_node)`
2. Связывает старый хвост и свой узел: `prev_tail->next = new_node`

Выполнив первый шаг, поток зафиксировал концы стрелки в односвязном списке, но еще не протянул между ними указатель.

Захваченный хвост после первого шага больше не виден другим потокам. Два разных потока не могут увидеть один и тот же `tail`, потому что вместе с чтением они перезаписывают его атомарной RMW-операцией `exchange`.

Такой список может распадаться на несколько сегментов или даже на отдельные узлы, если планировщик будет переключать потоки между первым и вторым шагом вставки.
Но рано или поздно связи возникнут. Впрочем, неизвестно, в каком именно порядке...

Извлечение элементов из такой очереди – несложная задача в предположении *single consumer*, нужно лишь аккуратно обойти граничный случай пустой очереди. Но мы проигнорируем эту операцию, потому что в спинлоке она будет устроена проще.


## Очередь ожидания

Покажем, как применить описанную выше очередь / список для реализации очереди ожидания в спинлоке.

Каждый поток, который ждет своей очереди на спинлоке, будет представлен в списке узлом с двумя полями: 
* `next` – указатель на следующий узел списка, и 
* `is_owner` – флаг – владеет ли спинлоком в данный момент поток-хозяин данного узла.

`Lock` устроен так:

1. Поток добавляет свой узел в хвост списка.
2. Крутится на флаге `is_owner` своего узла, ожидая, когда в него передадут владение спинлоком, либо (если список был пуст на момент вставки узла) просто проходит в критическую секцию (поскольку других претендентов нет).

Выходя из критической секции, поток должен передать владение спинлоком следующему потоку в очереди, если такой есть.

## Интрузивность

Как правило, узлы списков размещают в динамической памяти. Мы будем размещать их прямо на стеках потоков.

У спинлока не будет публичных методов `Lock` и `Unlock`.

Захват спинлока происходит с помощью конструирования экземпляра `QueueSpinLock::Guard`, после чего критическая секция продолжается до момента разрушения этого гарда (до выхода из скоупа, в котором гард был создан).

Пример:

```cpp
QueueSpinLock spinlock;

{
    QueueSpinLock::Guard guard{spinlock};  // <-- Acquire
    // Critical section
}  // <-- Release
```

`QueueSpinLock::Guard` – это и есть узел, который будет добавлен в очередь ожидания. В конструкторе `Guard` прицепит сам себя в конец очереди ожидания спинлока, а в деструкторе – передаст блокировку следующему гарду в очереди.

Хранить указатель на голову очереди ожидания в спинлоке не нужно: поток извлекает свой узел из очереди в тот момент, когда этот узел является головой.

Список потоков в спинлоке называется _интрузивным_ (_intrusive_): он не управляет временем жизни узлов, не аллоцирует и не освобождает динамическую память для них, он лишь связывает внешние объекты, в которые встроены указатели.

## References

* [Memory Barriers: a Hardware View for Software Hackers](http://www.cs.otago.ac.nz/cosc440/readings/HWMB.pdf) – подробный разбор устройства кэшей, протокола MESI, примеры оптимизаций, которые влияют на упорядочивние обращений к памяти
* [MESI cache coherence protocol simulator](https://www.scss.tcd.ie/~jones/vivio/caches/ALL%20protocols.htm)
* [Measuring CPU core-to-core latency](https://github.com/nviennot/core-to-core-latency)
* [Evaluating the Cost of Atomic Operations on Modern Architectures](https://spcl.inf.ethz.ch/Publications/.pdf/atomic-bench.pdf)

## Linux

Найдите реализацию этого спинлока [в ядре Linux](https://github.com/torvalds/linux/tree/master/kernel/locking).
